# -*- coding: utf-8 -*-
"""FaceCluster_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1elmyBCavyVcZgxRzFwN6I06KVfM0oSUN
"""

# from google.colab import drive
# drive.mount('/content/drive')
#
# !ls '/content/drive/MyDrive/faceCluster_5'
#
# !pip3 install opencv-python argparse imutils face-recognition dlib scikit-learn

import cv2
import argparse
import imutils
import glob
import matplotlib.pyplot as plt
import face_recognition
import os
import numpy as np
import sys
import json
import pandas as pd

# from google.colab import files

image_types = (".jpg", ".jpeg", ".png", ".bmp", ".tif", ".tiff")


def list_images(basePath, contains=None):
    # return the set of files that are valid
    return list_files(basePath, validExts=image_types, contains=contains)


def list_files(basePath, validExts=None, contains=None):
    # loop over the directory structure
    for (rootDir, dirNames, filenames) in os.walk(basePath):
        # loop over the filenames in the current directory
        for filename in filenames:
            # if the contains string is not none and the filename does not contain
            # the supplied string, then ignore the file
            if contains is not None and filename.find(contains) == -1:
                continue

            # determine the file extension of the current file
            ext = filename[filename.rfind("."):].lower()

            # check to see if the file is an image and should be processed
            if validExts is None or ext.endswith(validExts):
                # construct the path to the image and yield it
                imagePath = os.path.join(rootDir, filename)
                yield imagePath


path = input("Please enter the image folder path ")  # current path: /content/drive/MyDrive/faceCluster_5
print(path[-1])
number_of_clusters = int(path[-1])
imagePaths = list(list_images(path))
print(len(imagePaths))
model = cv2.CascadeClassifier('./Model_Files/haarcascade_frontalface_default.xml')
data = []
image_name = []
box_append = []
element_list = []
face_cluster = []

for (i, imagePath) in enumerate(imagePaths):
    image = cv2.imread(imagePath)
    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    boxes = model.detectMultiScale(gray, 1.2, 5)

    for x, y, w, h in boxes:
        cv2.rectangle(rgb, (x, y), (x + w, y + h), (0, 255, 0), 2)
        r = max(w, h) / 2
        centerx = x + w / 2
        centery = y + h / 2
        nx = int(centerx - r)
        ny = int(centery - r)
        nr = int(r * 2)
        faceimg = rgb[ny:ny + nr, nx:nx + nr]
        print('shape', faceimg.shape)
        h_, w_, c_ = faceimg.shape
        print('width:  ', w_)
        print('height: ', h_)
        print('channel:', c_)
        box_f = [(0, 0 + w_, 0 + h_, 0)]
        encodings = face_recognition.face_encodings(faceimg, box_f)

    face_cluster.append(faceimg)
    data.append(encodings)
    image_name.append(imagePath)
    box_append.append(box_f)

    image_file_name = imagePath[len(path) + 1:]
    print('image_file_name', image_file_name)
    element_list.append(image_file_name)

    plt.imshow(faceimg)
    plt.show()

np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)
data = np.array(data).reshape(len(imagePaths), 128)
data.shape
print(box_append)
print(element_list)

np.random.seed(42)


def euclidean_distance(x1, x2):
    return np.sqrt(np.sum((x1 - x2) ** 2))


# function to compute distance
def distance(p1, p2):
    return np.sum((p1 - p2) ** 2)


class KMeans():

    def __init__(self, K=number_of_clusters, max_iters=50, plot_steps=False):
        self.K = K

        self.max_iters = max_iters
        self.plot_steps = plot_steps

        # list of sample indices for each cluster
        self.clusters = [[] for _ in range(self.K)]
        # the centers (mean feature vector) for each cluster
        self.centroids = []

    def predict(self, X):
        self.X = X
        self.n_samples, self.n_features = X.shape

        # initialize
        random_sample_idxs = np.random.choice(self.n_samples, self.K, replace=False)
        # self.centroids = initialize(data, k = number_of_clusters)
        self.centroids.append(X[np.random.randint(X.shape[0]), :])
        for c_id in range(self.K - 1):
            dist = []
            for i in range(X.shape[0]):
                point = data[i, :]
                d = sys.maxsize
                for j in range(len(self.centroids)):
                    temp_dist = distance(point, self.centroids[j])
                    d = min(d, temp_dist)
                dist.append(d)
            dist = np.array(dist)
            next_centroid = data[np.argmax(dist), :]
            self.centroids.append(next_centroid)
            dist = []

        # Optimize clusters
        for _ in range(self.max_iters):
            # Assign samples to closest centroids (create clusters)
            self.clusters = [[] for _ in range(self.K)]
            for idx, sample in enumerate(self.X):
                centroid_idx = [euclidean_distance(sample, point) for point in self.centroids]
                centroid_idx = np.argmin(centroid_idx)
                self.clusters[centroid_idx].append(idx)
            # self.clusters = self._create_clusters(self.centroids)

            if self.plot_steps:
                self.plot()

            # Calculate new centroids from the clusters
            centroids_old = self.centroids
            self.centroids = np.zeros((self.K, self.n_features))
            for cluster_idx, cluster in enumerate(self.clusters):
                cluster_mean = np.mean(self.X[cluster], axis=0)
                self.centroids[cluster_idx] = cluster_mean

            # check if clusters have changed
            _is_converged_distances = [euclidean_distance(centroids_old[i], self.centroids[i]) for i in range(self.K)]
            if sum(_is_converged_distances) == 0:
                break

            if self.plot_steps:
                self.plot()

        # Classify samples as the index of their clusters
        cluster_labels = np.empty(self.n_samples)

        for cluster_index, cluster in enumerate(self.clusters):
            for sample_index in cluster:
                cluster_labels[sample_index] = cluster_index
        return cluster_labels

    def plot(self):
        fig, ax = plt.subplots(figsize=(12, 8))

        for i, index in enumerate(self.clusters):
            point = self.X[index].T
            ax.scatter(*point)

        for point in self.centroids:
            ax.scatter(*point, marker="x", color='black', linewidth=2)

        plt.show()


KM = KMeans()
cluster = KM.predict(data)

cluster = cluster.astype('int')
cluster

labelIDs = np.unique(cluster)
numUniqueFaces = len(np.where(labelIDs > -1)[0])
print(labelIDs)
print(numUniqueFaces)

for labelID in labelIDs:
    index = np.where(cluster == labelID)[0]
    index = np.random.choice(index, size=min(25, len(index)), replace=False)
    faces = []

    for a in index:
        print('a', a)
        img = cv2.imread(image_name[a])
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        face = face_cluster[a]
        # print('face', face.shape)

        try:
            face = cv2.resize(face, (80, 80), interpolation=cv2.INTER_AREA)
        except:
            break
        height, width, layers = face.shape
        size = (width, height)
        print('size', size)
        faces.append(face)
        print('length', len(faces))
        title = "Face ID #{}".format(labelID)
        title = "Unknown Faces" if labelID == -1 else title
        plt.title(title)
        if len(faces) > 1:
            concatenate_image = np.concatenate((faces[0], faces[1]), axis=1)
            if len(faces) > 2:
                for i in range(2, len(faces)):
                    concatenate_image = np.concatenate((concatenate_image, faces[i]), axis=1)
            plt.imshow(concatenate_image)
            plt.show()
        else:
            plt.imshow(faces[0])
            plt.show()

json_list = []
for i in range(0, number_of_clusters):
    temp = []
    for j in range(0, len(cluster)):
        if i == cluster[j]:
            temp.append(element_list[j])
            data = {"cluster_no": int(i), "elements": temp}
    json_list.append(data)

print(json_list)
output_json = "clusters.json"
with open(output_json, 'w') as f:
    json.dump(json_list, f)
